name: Scheduled Price Scraper

on:
  schedule:
    # Runs every day at 0:00 UTC
    - cron: '0 0 * * *'
  workflow_dispatch: # Allows manual triggering from GitHub UI

jobs:
  scrape-prices:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x' # Use your desired Python version

      - name: Install Python dependencies
        run: |
          pip install playwright google-api-python-client google-auth-oauthlib google-auth-httplib2
        timeout-minutes: 5 # Give pip install more time, though it's usually fast

      - name: Install Playwright browsers
        run: |
          playwright install chromium # Explicitly install only chromium
        timeout-minutes: 10 # Give Playwright browser download/install more time

      - name: Create Service Account Key File
        env:
          SA_KEY_JSON: ${{ secrets.SA_KEY_JSON }}
        run: |
          echo "$SA_KEY_JSON" > sheet-scraper-as.json

      - name: Run Price Scraper
        env:
          SPREADSHEET_ID: ${{ secrets.SPREADSHEET_ID }}
        run: |
          python -c "print('Python interpreter is working!')" # ADD THIS LINE
          python sheet_scraper.py